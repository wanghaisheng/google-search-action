name: Daily App Opportunity Hunter (External Script V8)

on:
  workflow_dispatch:
    inputs:
      paywall_anger_query:
        description: 'Query for paywall anger detector'
        required: false
        default: '{category} app paywall scam subscription trap forced to pay rip off overpriced worthless'
      uninstall_intention_query:
        description: 'Query for uninstall intention detector'
        required: false
        default: '{category} app how to cancel subscription how to uninstall'
      worth_it_review_query:
        description: 'Query for worth it review detector'
        required: false
        default: '{category} app worth it review alternatives to best free'
      categories:
        description: 'Comma-separated list of categories (leave empty for broad search)'
        required: false
        default: ''
      timeframe:
        description: 'Timeframe for the search (qdr:h, qdr:d, qdr:w, qdr:m, qdr:y)'
        required: false
        default: 'qdr:d'

jobs:
  hunt-for-apps:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install "googlesearch-python" pandas beautifulsoup4 requests

      - name: Run Google Search Scraper (CSV)
        id: scraper
        run: |
          # Define detectors here; the queries will be passed as inputs
          detectors='{ "paywall_anger": "${{ github.event.inputs.paywall_anger_query }}", "uninstall_intention": "${{ github.event.inputs.uninstall_intention_query }}", "worth_it_review": "${{ github.event.inputs.worth_it_review_query }}" }'

          # Categories are comma-separated in inputs
          categories="${{ github.event.inputs.categories }}"
          if [[ -z "$categories" ]]; then
             categories_array=("") # Empty array for broad search
          else
             IFS=',' read -r -a categories_array <<< "$categories"
          fi

          timeframe="${{ github.event.inputs.timeframe }}"

          # Loop through each detector and category to run the scraper
          for detector_name in $(echo "$detectors" | jq -r 'keys[]')
          do
            detector_query=$(echo "$detectors" | jq -r ".${detector_name}")

            for category in "${categories_array[@]}"
            do
               if [[ -z "$category" ]]; then
                  query="$detector_query"  # Use the raw query for broad search
               else
                  query=$(echo "$detector_query" | sed "s/\\{category\\}/$category/g") # Replace {category}
               fi
               #Execute the scraper with the dynamically created arguments
               python csv_scraper.py "$query" "$timeframe" "$detector_name" "$category"
            done
          done

      - name: Commit and Push CSV Results
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "CI: Daily App Opportunity Hunter (External Script V8)"
          file_pattern: "results/*.csv"  # Track all CSV files in "results"
          commit_user_name: "GitHub Actions Bot"
          commit_user_email: "actions@github.com"
          commit_author: "GitHub Actions Bot <actions@github.com>"
